{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install pedalboard\n",
    "\n",
    "# TO USE: \n",
    "#    1. Upload your input and output wav files to the current directory in Colab\n",
    "#    2. Edit the USER INPUTS section to point to your wav files, and choose a\n",
    "#         model name, and number of epochs for training. \n",
    "#    3. Run each section of code. The trained models and output wav files will be \n",
    "#         added to the \"models\" directory.\n",
    "#\n",
    "#     Note: Tested on CPU and GPU runtimes.\n",
    "#     Note: Uses MSE for loss calculation instead of Error to Signal with Pre-emphasis filter\n",
    "\n",
    "'''This is a similar Tensorflow/Keras implementation of the LSTM model from the paper:\n",
    "    \"Real-Time Guitar Amplifier Emulation with Deep Learning\"\n",
    "    https://www.mdpi.com/2076-3417/10/3/766/htm\n",
    "\n",
    "    Uses a stack of two 1-D Convolutional layers, followed by LSTM, followed by \n",
    "    a Dense (fully connected) layer. Three preset training modes are available, \n",
    "    with further customization by editing the code. A Sequential tf.keras model \n",
    "    is implemented here.\n",
    "\n",
    "    Note: RAM may be a limiting factor for the parameter \"input_size\". The wav data\n",
    "      is preprocessed and stored in RAM, which improves training speed but quickly runs out\n",
    "      if using a large number for \"input_size\".  Reduce this if you are experiencing\n",
    "      RAM issues. \n",
    "    \n",
    "    --training_mode=0   Speed training (default)\n",
    "    --training_mode=1   Accuracy training\n",
    "    --training_mode=2   Extended training (set max_epochs as desired, for example 50+)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import clear_session\n",
    "#from tensorflow.keras.activations import tanh, elu, relu\n",
    "#from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#import math\n",
    "import h5py\n",
    "import librosa\n",
    "from pedalboard import (\n",
    "    Pedalboard,\n",
    "    Convolution,\n",
    "    Compressor,\n",
    "    Chorus,\n",
    "    Distortion,\n",
    "    Gain,\n",
    "    Reverb,\n",
    "    Limiter,\n",
    "    LadderFilter,\n",
    "    Phaser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS SECTION FOR USER INPUTS\n",
    "#\n",
    "\n",
    "name = 'Chorus_Test'\n",
    "if not os.path.exists('models/'+name):\n",
    "    os.makedirs('models/'+name)\n",
    "else:\n",
    "    print(\"A model with the same name already exists. Please choose a new name.\")\n",
    "    exit\n",
    "\n",
    "epochs = 20\n",
    "fs = 44100\n",
    "train_mode = 0     # 0 = speed training, \n",
    "                   # 1 = accuracy training \n",
    "                   # 2 = extended training\n",
    "\n",
    "batch_size = 4 \n",
    "test_size = 0.2\n",
    "input_size = 100\n",
    "\n",
    "if train_mode == 0:         # Speed Training\n",
    "    learning_rate = 0.01 \n",
    "    conv1d_strides = 12    \n",
    "    conv1d_filters = 16\n",
    "    hidden_units = 36\n",
    "elif train_mode == 1:       # Accuracy Training (~10x longer than Speed Training)\n",
    "    learning_rate = 0.01 \n",
    "    conv1d_strides = 4\n",
    "    conv1d_filters = 36\n",
    "    hidden_units= 64\n",
    "else:                       # Extended Training (~60x longer than Accuracy Training)\n",
    "    learning_rate = 0.0005 \n",
    "    conv1d_strides = 3\n",
    "    conv1d_filters = 36\n",
    "    hidden_units= 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowArray(Sequence):\n",
    "        \n",
    "    def __init__(self, x, y, window_len, batch_size=32):\n",
    "        self.x = x\n",
    "        self.y = y[window_len-1:] \n",
    "        self.window_len = window_len\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        l = len(self.x)\n",
    "        #return (len(self.x[0]) - self.window_len +1) // self.batch_size\n",
    "        return (len(self.x) - self.window_len +1) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x_out = np.stack([self.x[idx: idx+self.window_len] for idx in range(index*self.batch_size, (index+1)*self.batch_size)])\n",
    "        y_out = self.y[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return x_out, y_out\n",
    "\n",
    "def pre_emphasis_filter(x, coeff=0.95):\n",
    "    return tf.concat([x, x - coeff * x], 1)\n",
    "    \n",
    "def error_to_signal(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Error to signal ratio with pre-emphasis filter:\n",
    "    \"\"\"\n",
    "    y_true, y_pred = pre_emphasis_filter(y_true), pre_emphasis_filter(y_pred)\n",
    "    return K.sum(tf.pow(y_true - y_pred, 2), axis=0) / (K.sum(tf.pow(y_true, 2), axis=0) + 1e-10)\n",
    "    \n",
    "def save_wav(name, data):\n",
    "    wavfile.write(name, fs, data.flatten().astype(np.float32))\n",
    "\n",
    "# normalize data to loudest signal\n",
    "def normalize(data):\n",
    "    data_max = max(data)\n",
    "    data_min = min(data)\n",
    "    data_norm = max(data_max,abs(data_min))\n",
    "    return data / data_norm\n",
    "\n",
    "# add fadeout with length samples   \n",
    "def apply_fadeout(audio, length):\n",
    "    # convert to audio indices (samples)\n",
    "    #length = int(duration*sr)\n",
    "    end = len(audio)\n",
    "    start = end - length\n",
    "\n",
    "    # compute fade out curve\n",
    "    # linear fade\n",
    "    fade_curve = np.linspace(1.0, 0.0, length)\n",
    "    audio[start:end] = audio[start:end] *fade_curve\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sequential Model ###########################################\n",
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv1d_filters, 12,strides=conv1d_strides, activation=None, padding='same',input_shape=(input_size,1)))\n",
    "model.add(Conv1D(conv1d_filters, 12,strides=conv1d_strides, activation=None, padding='same'))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation=None))\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=[error_to_signal])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = dry[:100].astype(np.float32).flatten()  \n",
    "X_all = normalize(X_all).reshape(len(X_all),1)   \n",
    "y_all = wet[:100].astype(np.float32).flatten() \n",
    "y_all = normalize(y_all).reshape(len(y_all),1)\n",
    "train_examples = int(len(X_all)*0.8)\n",
    "train_arr = WindowArray(X_all[:train_examples], y_all[:train_examples], input_size, batch_size=batch_size)\n",
    "val_arr = WindowArray(X_all[train_examples:], y_all[train_examples:], input_size, batch_size=batch_size)\n",
    "print(train_arr.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Sequential Model ###################################################\n",
    "history = model.fit(train_arr, validation_data=val_arr, epochs=epochs, shuffle=True)    \n",
    "model.save('models/'+name+'/'+name+'.h5')\n",
    "\n",
    "# Run Prediction #################################################\n",
    "print(\"Running prediction..\")\n",
    "\n",
    "# Get the last 20% of the wav data to run prediction and plot results\n",
    "y_the_rest, y_last_part = np.split(y_all, [int(len(y_all)*.8)])\n",
    "x_the_rest, x_last_part = np.split(X_all, [int(len(X_all)*.8)])\n",
    "y_test = y_last_part[input_size-1:] \n",
    "test_arr = WindowArray(x_last_part, y_last_part, input_size, batch_size = batch_size)\n",
    "\n",
    "prediction = model.predict(test_arr)\n",
    "\n",
    "save_wav('models/'+name+'/y_pred.wav', prediction)\n",
    "save_wav('models/'+name+'/x_test.wav', x_last_part)\n",
    "save_wav('models/'+name+'/y_test.wav', y_test)\n",
    "\n",
    "# Add additional data to the saved model (like input_size)\n",
    "filename = 'models/'+name+'/'+name+'.h5'\n",
    "f = h5py.File(filename, 'a')\n",
    "grp = f.create_group(\"info\")\n",
    "dset = grp.create_dataset(\"input_size\", (1,), dtype='int16')\n",
    "dset[0] = input_size\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing losses and accuracy\n",
    "train_loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "#train_acc, val_acc = history.history['accuracy'], history.history['val_accuracy']\n",
    "\n",
    "# setup plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(15,5))\n",
    " \n",
    "# plot loss\n",
    "ax[0].plot(range(epochs), train_loss)\n",
    "ax[0].plot(range(epochs), val_loss)\n",
    "ax[0].set_ylabel('loss')\n",
    "ax[0].set_title('train_loss vs val_loss')\n",
    "\n",
    "# plot accuracy\n",
    "#ax[1].plot(range(epochs), train_acc)\n",
    "#ax[1].plot(range(epochs), val_acc)\n",
    "#ax[1].set_ylabel('accuracy')\n",
    "#ax[1].set_title('train_acc vs val_acc')\n",
    "\n",
    "# plot adjustement\n",
    "for a in ax:\n",
    "    a.grid(True)\n",
    "    a.legend(['train','val'],loc=4)\n",
    "    a.set_xlabel('num of Epochs')\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
